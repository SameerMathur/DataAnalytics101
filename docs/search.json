[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
<<<<<<< HEAD
    "text": "WS20. Exploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. EDA is primarily for seeing what the data can tell us beyond the formal modeling or hypothesis testing tasks.\nThe EDA approach can be broken down into the following steps:\nData Cleaning: This step includes handling missing data, removing outliers, and other data cleansing processes.\nUnivariate Analysis: Here, each field in the dataset is analyzed independently to better understand its distribution, outliers, and unique values. This could involve statistical plots for measuring central tendency like mean, median, mode, frequency distribution, quartiles, etc.\nBivariate Analysis: This step involves the analysis of two variables to determine the empirical relationship between them. It includes techniques such as scatter plots for continuous variables or crosstabs for categorical data.\nMultivariate Analysis: This is an advanced step, involving analysis with more than two variables. It helps to understand the interactions between different fields in the dataset.\nData Visualization: This is the creation of plots such as histograms, box plots, scatter plots, etc., to identify patterns, relationships, or outliers within the dataset. This can be done using visualization tools or libraries.\nInsight Generation: After visualizations and some statistical tests, analysts will generate insights that could lead to further questions, hypotheses, and model building.\nThe EDA process is an important precursor to more complex analyses because it allows for the researcher to confirm or invalidate some initial hypotheses and to formulate a more precise question or hypothesis that can lead to further statistical analysis and testing.\n\n\n\nWe ignore the Data Cleaning step, although we acknowledge it’s practical relevance. We assume that we are working with a clean dataset.\nWe emphasize Univariate and Bivariate Analysis of data and the corresponding Data Visualization.\nWe cover some basic Multivariate Analysis.\nWe emphasize Insight Generation.\n\nWe illustrate all of the above using the R programming language.\nWe further illustrate how to use R programming on a real-world dataset. Our dataset concerns the S&P500 stocks. This will demonstrate a practical aspect of using this book. We have many sample codes regarding this, using real-world data.. We will explore financial metrics such as the Return on Equity , Return on Assets, Return on Invested Capital of S&P500 shares."
=======
    "text": "WS19. Exploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods. EDA is primarily for seeing what the data can tell us beyond the formal modeling or hypothesis testing tasks.\nThe EDA approach can be broken down into the following steps:\nData Cleaning: This step includes handling missing data, removing outliers, and other data cleansing processes.\nUnivariate Analysis: Here, each field in the dataset is analyzed independently to better understand its distribution, outliers, and unique values. This could involve statistical plots for measuring central tendency like mean, median, mode, frequency distribution, quartiles, etc.\nBivariate Analysis: This step involves the analysis of two variables to determine the empirical relationship between them. It includes techniques such as scatter plots for continuous variables or crosstabs for categorical data.\nMultivariate Analysis: This is an advanced step, involving analysis with more than two variables. It helps to understand the interactions between different fields in the dataset.\nData Visualization: This is the creation of plots such as histograms, box plots, scatter plots, etc., to identify patterns, relationships, or outliers within the dataset. This can be done using visualization tools or libraries.\nInsight Generation: After visualizations and some statistical tests, analysts will generate insights that could lead to further questions, hypotheses, and model building.\nThe EDA process is an important precursor to more complex analyses because it allows for the researcher to confirm or invalidate some initial hypotheses and to formulate a more precise question or hypothesis that can lead to further statistical analysis and testing.\n\n\n\nWe ignore the Data Cleaning step, although we acknowledge it’s practical relevance. We assume that we are working with a clean dataset.\nWe emphasize Univariate and Bivariate Analysis of data and the corresponding Data Visualization.\nWe cover some basic Multivariate Analysis.\nWe emphasize Insight Generation.\n\nWe illustrate all of the above using the R programming language.\nWe further illustrate how to use R programming on a real-world dataset. Our dataset concerns the S&P500 stocks. This will demonstrate a practical aspect of using this book. We have many sample codes regarding this, using real-world data.. We will explore financial metrics such as the Return on Equity , Return on Assets, Return on Invested Capital of S&P500 shares."
>>>>>>> bd4d1d914cc753ec0eeca26119be15ad085871ec
  },
  {
    "objectID": "index.html#our-focus",
    "href": "index.html#our-focus",
    "title": "Preface",
    "section": "",
    "text": "We ignore the Data Cleaning step, although we acknowledge it’s practical relevance. We assume that we are working with a clean dataset.\nWe emphasize Univariate and Bivariate Analysis of data and the corresponding Data Visualization.\nWe cover some basic Multivariate Analysis.\nWe emphasize Insight Generation.\n\nWe illustrate all of the above using the R programming language.\nWe further illustrate how to use R programming on a real-world dataset. Our dataset concerns the S&P500 stocks. This will demonstrate a practical aspect of using this book. We have many sample codes regarding this, using real-world data.. We will explore financial metrics such as the Return on Equity , Return on Assets, Return on Invested Capital of S&P500 shares."
  },
  {
    "objectID": "01OverviewOfR.html",
    "href": "01OverviewOfR.html",
    "title": "Getting Started",
    "section": "",
    "text": "R is an open-source software environment and programming language designed for statistical computing, data analysis, and visualization. It was developed by Ross Ihaka and Robert Gentleman at the University of Auckland in New Zealand during the early 1990s.\nR offers a wide range of statistical techniques, including linear and nonlinear modeling, classical statistical tests, and support for data manipulation, data import/export, and compatibility with various data formats.\nR offers free usage, distribution, and modification, making it accessible to individuals with various budgets and resources who wish to learn and utilize it.\nThe Comprehensive R Archive Network (CRAN) serves as a valuable resource for the R programming language. It offers a vast collection of downloadable packages that expand the functionality of R, including tools for machine learning, data mining, and visualization.\nR stands out as a prominent tool within the data analysis community, attracting a large and active user base. This community plays a vital role in the ongoing maintenance and development of R packages, ensuring a thriving ecosystem for continuous improvement.\nOne of R’s strengths lies in its powerful and flexible graphics system, empowering users to create visually appealing and informative data visualizations for data exploration, analysis, and effective communication.\nR facilitates the creation of shareable and reproducible scripts, promoting transparency and enabling seamless collaboration on data analysis projects. This feature enhances the ability to replicate and validate results, fostering trust and credibility in the analysis process.\nR exhibits strong compatibility with other programming languages like Python and SQL, as well as with popular data storage and manipulation tools such as Hadoop and Spark. This compatibility allows for smooth integration and interoperability, enabling users to leverage the strengths of multiple tools and technologies for their data-centric tasks. [1]\n\n\n\n\nR could be run locally or in the Cloud. We discuss running R locally. We discuss running it in the Cloud in the next sub-section.\n\n\nBefore running R locally, we need to first install R locally. Here are general instructions to install R locally on your computer:\\\n\nVisit the official website of the R project at https://www.r-project.org/.\nOn the download page, select the appropriate version of R based on your operating system (Windows, Mac, or Linux).\nAfter choosing your operating system, click on a mirror link to download R from a reliable source.\nOnce the download is finished, locate the downloaded file and double-click on it to initiate the installation process. Follow the provided instructions to complete the installation of R on your computer. [2]\n\n\n\n\nAn Integrated Development Environment (IDE) is a software application designed to assist in software development by providing a wide range of tools and features. These tools typically include a text editor, a compiler or interpreter, debugging tools, and various utilities that aid developers in writing, testing, and debugging their code.\nWhen working with the R programming language on your local machine and looking to take advantage of IDE features, you have several options available:\n\nRStudio: RStudio is a highly popular open-source IDE specifically tailored for R programming. It boasts a user-friendly interface, a code editor with features like syntax highlighting and code completion, as well as powerful debugging capabilities. RStudio also integrates seamlessly with version control systems and package management tools, making it an all-inclusive IDE for R development.\nVisual Studio Code (VS Code): While primarily recognized as a versatile code editor, VS Code also offers excellent support for R programming through extensions. By installing the “R” extension from the Visual Studio Code marketplace, you can enhance your experience with R-specific functionality, such as syntax highlighting, code formatting, and debugging support.\nJupyter Notebook: Jupyter Notebook is an open-source web-based environment that supports multiple programming languages, including R. It provides an interactive interface where you can write and execute R code within individual cells. Jupyter Notebook is widely employed for data analysis and exploration tasks due to its ability to blend code, visualizations, and text explanations seamlessly.\n\nThese IDE options vary in their features and user interfaces, allowing you to choose the one that aligns best with your specific needs and preferences. It’s important to note that while R can also be run through the command line or the built-in R console, utilizing an IDE can significantly boost your productivity and enhance your overall development experience. [3]\n\n\n\nRStudio is a highly popular integrated development environment (IDE) designed specifically for R programming. It offers a user-friendly interface and a comprehensive set of tools for data analysis, visualization, and modeling using R.\nSome notable features of RStudio include:\n\nCode editor: RStudio includes a code editor with advanced features such as syntax highlighting, code completion, and other functionalities that simplify the process of writing R code.\nData viewer: RStudio provides a convenient data viewer that allows users to examine and explore their data in a tabular format, facilitating data analysis.\nPlots pane: The plots pane in RStudio displays graphical outputs generated by R code, making it easy for users to visualize their data and analyze results.\nConsole pane: RStudio includes a console pane that shows R code and its corresponding output. It enables users to execute R commands interactively, enhancing the coding experience.\nPackage management: RStudio offers tools for managing R packages, including installation, updating, and removal of packages. This simplifies the process of working with external libraries and extending the functionality of R.\nVersion control: RStudio seamlessly integrates with version control systems like Git, empowering users to efficiently manage and collaborate on their code projects.\nShiny applications: RStudio allows users to create interactive web applications using Shiny, a web development utility for R. This feature enables the creation of dynamic and user-friendly interfaces for R-based applications. [4]\n\nTo install RStudio on your computer, you can follow these simple steps:\n\nDownload RStudio: Visit the RStudio download page and choose the version of RStudio that matches your operating system.\nInstall RStudio: Once the RStudio installer is downloaded, run it and follow the instructions provided to complete the installation process on your computer.\nOpen RStudio: After the installation is finished, you can open RStudio by double-clicking the RStudio icon on your desktop or in the Applications folder.\nStart an R session: In RStudio, click on the Console tab to initiate an R session. You can then enter R commands in the console and execute them by clicking the “Run” button or using the shortcut Ctrl+Enter (Windows) or Cmd+Enter (Mac). [5]\n\n\n\n\n\nRunning R in the cloud allows users to access R and RStudio from anywhere with an internet connection, eliminating the need to install R locally. Several cloud service providers, such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP), offer virtual machines (VMs) with pre-installed R and RStudio.\nHere are some key advantages and disadvantages of running R in the cloud:\nBenefits:\n\nScalability: Cloud providers offer scalable computing resources that can be adjusted to meet specific workload requirements. This is particularly useful for data-intensive tasks that require significant computational power.\nAccessibility and Collaboration: Cloud-based R allows users to access R and RStudio from any location with an internet connection, facilitating collaboration on projects and data sharing.\nCost-effectiveness: Cloud providers offer flexible pricing models that can be more cost-effective than running R on local hardware, especially for short-term or infrequent use cases.\nSecurity: Cloud service providers implement various security features, such as firewalls and encryption, to protect data and applications from unauthorized access or attacks. [6]\n\nDrawbacks:\n\nInternet Dependency: Running R in the cloud relies on a stable internet connection, which may not be available at all times or in all locations. This can limit the ability to work on data analysis and modeling projects.\nLearning Curve: Utilizing cloud computing platforms and tools requires familiarity, which can pose a learning curve for users new to cloud computing.\nData Privacy: Storing data in the cloud may raise concerns about data privacy, particularly for sensitive or confidential information. While cloud service providers offer security features, users must understand the risks and take appropriate measures to secure their data.\nCost Considerations: While cloud computing can be cost-effective in certain scenarios, it can also become expensive for long-term or high-volume use cases, especially if additional resources like data storage are required alongside computational capacity. [6]\n\n\n\nHere is a comparison of four prominent cloud service providers: Posit, AWS, Azure, and GCP.\nPosit:\n\nPosit is a relatively new cloud service provider that focuses on offering high-performance computing resources specifically for data-intensive applications.\nThey provide bare-metal instances that ensure superior performance and flexibility.\nPosit is dedicated to data security and compliance, prioritizing the protection of user data.\nThey offer customizable hardware configurations tailored to meet specific application requirements.\n\nAWS:\n\nAWS is a well-established cloud service provider that offers a wide range of cloud computing services, including computing, storage, and database services.\nIt boasts a large and active user community, providing abundant resources and support for users.\nAWS provides flexible pricing options, including pay-as-you-go and reserved instance pricing.\nThey offer a comprehensive set of tools and services for managing and securing cloud-based applications.\n\nAzure:\n\nAzure is another leading cloud service provider that offers various cloud computing services, including computing, storage, and networking.\nIt tightly integrates with Microsoft’s enterprise software and services, making it an attractive option for organizations using Microsoft technologies.\nAzure provides flexible pricing models, including pay-as-you-go, reserved instance, and spot instance pricing.\nThey offer a wide array of tools and services for managing and securing cloud-based applications.\n\nGCP:\n\nGCP is a cloud service provider that provides a comprehensive suite of cloud computing services, including computing, storage, and networking.\nIt offers specialized tools and services for machine learning and artificial intelligence applications.\nGCP provides flexible pricing options, including pay-as-you-go and sustained use pricing.\nThey offer a range of tools and services for managing and securing cloud-based applications. [7]\n\n\n\n\n\n[1] Chambers, J. M. (2016). Extending R (2nd ed.). CRC Press.\nGandrud, C. (2015). Reproducible research with R and RStudio. CRC Press.\nGrolemund, G., & Wickham, H. (2017). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media.\nIhaka, R., & Gentleman, R. (1996). R: A language for data analysis and graphics. Journal of Computational and Graphical Statistics, 5(3), 299-314. https://www.jstor.org/stable/1390807\nMurrell, P. (2006). R graphics. CRC Press.\nPeng, R. D. (2016). R programming for data science. O’Reilly Media.\nR Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/\nVenables, W. N., Smith, D. M., & R Development Core Team. (2019). An introduction to R. Network Theory Ltd. Retrieved from https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf\nWickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1-23.\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag.\nWickham, H., & Grolemund, G. (2017). R packages: Organize, test, document, and share your code. O’Reilly Media.\n[2] The R Project for Statistical Computing. (2021). Download R for (Mac) OS X. https://cran.r-project.org/bin/macosx/\nThe R Project for Statistical Computing. (2021). Download R for Windows. https://cran.r-project.org/bin/windows/base/\nThe R Project for Statistical Computing. (2021). Download R for Linux. https://cran.r-project.org/bin/linux/\n[3] Grant, E., & Allen, B. (2021). Integrated Development Environments: A Comprehensive Overview. Journal of Software Engineering, 16(3), 123-145. doi:10./jswe.2021.16.3.123\nJohnson, M. L., & Smith, R. W. (2022). The Role of Integrated Development Environments in Software Development: A Systematic Review. ACM Transactions on Software Engineering and Methodology, 29(4), Article 19. doi:10./tosem.2022.29.4.19\nRStudio, PBC. (n.d.). RStudio: Open source and enterprise-ready professional software for R. Retrieved July 3, 2023, from https://www.rstudio.com/\nMicrosoft. (n.d.). Visual Studio Code: Code Editing. Redefined. Retrieved July 3, 2023, from https://code.visualstudio.com/\nProject Jupyter. (n.d.). Jupyter: Open-source, interactive data science and scientific computing across over 40 programming languages. Retrieved July 3, 2023, from https://jupyter.org/\n[4] RStudio. (2021). RStudio. https://www.rstudio.com/\nRStudio. (2021). RStudio. https://www.rstudio.com/products/rstudio/features/\n[5] RStudio. (2021). RStudio. https://www.rstudio.com/products/rstudio/download/\n[6] Armbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R., Konwinski, A., … Zaharia, M. (2010). A view of cloud computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nXiao, Z., Chen, Z., & Zhang, J. (2014). Cloud computing research and security issues. Journal of Network and Computer Applications, 41, 1–11. https://doi.org/10.1016/j.jnca.2013.11.004\nCloud Spectator. (2021). Cloud Service Provider Pricing Models: A Comprehensive Guide. https://www.cloudspectator.com/cloud-service-provider-pricing-models-a-comprehensive-guide/\n[7] Amazon Web Services. (2021). AWS. https://aws.amazon.com/\nAmazon Web Services. (2021). Running RStudio Server Pro using Amazon EC2. https://docs.rstudio.com/rsp/quickstart/aws/\nAmazon Web Services. (2021). EC2 User Guide for Linux Instances. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html\nGoogle Cloud Platform. (2021). GCP. https://cloud.google.com/\nGoogle Cloud Platform. (2021). Compute Engine Documentation. https://cloud.google.com/compute/docs\nMicrosoft Azure. (2021). Azure. https://azure.microsoft.com/\nMicrosoft Azure. (2021). Create a Windows virtual machine with the Azure portal. https://docs.microsoft.com/en-us/azure/virtual-machines/windows/quick-create-portal\nPosit. (2021). High-Performance Computing Services. https://posit.cloud/"
  },
  {
    "objectID": "01OverviewOfR.html#overview-of-r-programming",
    "href": "01OverviewOfR.html#overview-of-r-programming",
    "title": "Getting Started",
    "section": "",
    "text": "R is an open-source software environment and programming language designed for statistical computing, data analysis, and visualization. It was developed by Ross Ihaka and Robert Gentleman at the University of Auckland in New Zealand during the early 1990s.\nR offers a wide range of statistical techniques, including linear and nonlinear modeling, classical statistical tests, and support for data manipulation, data import/export, and compatibility with various data formats.\nR offers free usage, distribution, and modification, making it accessible to individuals with various budgets and resources who wish to learn and utilize it.\nThe Comprehensive R Archive Network (CRAN) serves as a valuable resource for the R programming language. It offers a vast collection of downloadable packages that expand the functionality of R, including tools for machine learning, data mining, and visualization.\nR stands out as a prominent tool within the data analysis community, attracting a large and active user base. This community plays a vital role in the ongoing maintenance and development of R packages, ensuring a thriving ecosystem for continuous improvement.\nOne of R’s strengths lies in its powerful and flexible graphics system, empowering users to create visually appealing and informative data visualizations for data exploration, analysis, and effective communication.\nR facilitates the creation of shareable and reproducible scripts, promoting transparency and enabling seamless collaboration on data analysis projects. This feature enhances the ability to replicate and validate results, fostering trust and credibility in the analysis process.\nR exhibits strong compatibility with other programming languages like Python and SQL, as well as with popular data storage and manipulation tools such as Hadoop and Spark. This compatibility allows for smooth integration and interoperability, enabling users to leverage the strengths of multiple tools and technologies for their data-centric tasks. [1]"
  },
  {
    "objectID": "01OverviewOfR.html#running-r-locally",
    "href": "01OverviewOfR.html#running-r-locally",
    "title": "Getting Started",
    "section": "",
    "text": "R could be run locally or in the Cloud. We discuss running R locally. We discuss running it in the Cloud in the next sub-section.\n\n\nBefore running R locally, we need to first install R locally. Here are general instructions to install R locally on your computer:\\\n\nVisit the official website of the R project at https://www.r-project.org/.\nOn the download page, select the appropriate version of R based on your operating system (Windows, Mac, or Linux).\nAfter choosing your operating system, click on a mirror link to download R from a reliable source.\nOnce the download is finished, locate the downloaded file and double-click on it to initiate the installation process. Follow the provided instructions to complete the installation of R on your computer. [2]\n\n\n\n\nAn Integrated Development Environment (IDE) is a software application designed to assist in software development by providing a wide range of tools and features. These tools typically include a text editor, a compiler or interpreter, debugging tools, and various utilities that aid developers in writing, testing, and debugging their code.\nWhen working with the R programming language on your local machine and looking to take advantage of IDE features, you have several options available:\n\nRStudio: RStudio is a highly popular open-source IDE specifically tailored for R programming. It boasts a user-friendly interface, a code editor with features like syntax highlighting and code completion, as well as powerful debugging capabilities. RStudio also integrates seamlessly with version control systems and package management tools, making it an all-inclusive IDE for R development.\nVisual Studio Code (VS Code): While primarily recognized as a versatile code editor, VS Code also offers excellent support for R programming through extensions. By installing the “R” extension from the Visual Studio Code marketplace, you can enhance your experience with R-specific functionality, such as syntax highlighting, code formatting, and debugging support.\nJupyter Notebook: Jupyter Notebook is an open-source web-based environment that supports multiple programming languages, including R. It provides an interactive interface where you can write and execute R code within individual cells. Jupyter Notebook is widely employed for data analysis and exploration tasks due to its ability to blend code, visualizations, and text explanations seamlessly.\n\nThese IDE options vary in their features and user interfaces, allowing you to choose the one that aligns best with your specific needs and preferences. It’s important to note that while R can also be run through the command line or the built-in R console, utilizing an IDE can significantly boost your productivity and enhance your overall development experience. [3]\n\n\n\nRStudio is a highly popular integrated development environment (IDE) designed specifically for R programming. It offers a user-friendly interface and a comprehensive set of tools for data analysis, visualization, and modeling using R.\nSome notable features of RStudio include:\n\nCode editor: RStudio includes a code editor with advanced features such as syntax highlighting, code completion, and other functionalities that simplify the process of writing R code.\nData viewer: RStudio provides a convenient data viewer that allows users to examine and explore their data in a tabular format, facilitating data analysis.\nPlots pane: The plots pane in RStudio displays graphical outputs generated by R code, making it easy for users to visualize their data and analyze results.\nConsole pane: RStudio includes a console pane that shows R code and its corresponding output. It enables users to execute R commands interactively, enhancing the coding experience.\nPackage management: RStudio offers tools for managing R packages, including installation, updating, and removal of packages. This simplifies the process of working with external libraries and extending the functionality of R.\nVersion control: RStudio seamlessly integrates with version control systems like Git, empowering users to efficiently manage and collaborate on their code projects.\nShiny applications: RStudio allows users to create interactive web applications using Shiny, a web development utility for R. This feature enables the creation of dynamic and user-friendly interfaces for R-based applications. [4]\n\nTo install RStudio on your computer, you can follow these simple steps:\n\nDownload RStudio: Visit the RStudio download page and choose the version of RStudio that matches your operating system.\nInstall RStudio: Once the RStudio installer is downloaded, run it and follow the instructions provided to complete the installation process on your computer.\nOpen RStudio: After the installation is finished, you can open RStudio by double-clicking the RStudio icon on your desktop or in the Applications folder.\nStart an R session: In RStudio, click on the Console tab to initiate an R session. You can then enter R commands in the console and execute them by clicking the “Run” button or using the shortcut Ctrl+Enter (Windows) or Cmd+Enter (Mac). [5]"
  },
  {
    "objectID": "01OverviewOfR.html#running-r-in-the-cloud",
    "href": "01OverviewOfR.html#running-r-in-the-cloud",
    "title": "Getting Started",
    "section": "",
    "text": "Running R in the cloud allows users to access R and RStudio from anywhere with an internet connection, eliminating the need to install R locally. Several cloud service providers, such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP), offer virtual machines (VMs) with pre-installed R and RStudio.\nHere are some key advantages and disadvantages of running R in the cloud:\nBenefits:\n\nScalability: Cloud providers offer scalable computing resources that can be adjusted to meet specific workload requirements. This is particularly useful for data-intensive tasks that require significant computational power.\nAccessibility and Collaboration: Cloud-based R allows users to access R and RStudio from any location with an internet connection, facilitating collaboration on projects and data sharing.\nCost-effectiveness: Cloud providers offer flexible pricing models that can be more cost-effective than running R on local hardware, especially for short-term or infrequent use cases.\nSecurity: Cloud service providers implement various security features, such as firewalls and encryption, to protect data and applications from unauthorized access or attacks. [6]\n\nDrawbacks:\n\nInternet Dependency: Running R in the cloud relies on a stable internet connection, which may not be available at all times or in all locations. This can limit the ability to work on data analysis and modeling projects.\nLearning Curve: Utilizing cloud computing platforms and tools requires familiarity, which can pose a learning curve for users new to cloud computing.\nData Privacy: Storing data in the cloud may raise concerns about data privacy, particularly for sensitive or confidential information. While cloud service providers offer security features, users must understand the risks and take appropriate measures to secure their data.\nCost Considerations: While cloud computing can be cost-effective in certain scenarios, it can also become expensive for long-term or high-volume use cases, especially if additional resources like data storage are required alongside computational capacity. [6]\n\n\n\nHere is a comparison of four prominent cloud service providers: Posit, AWS, Azure, and GCP.\nPosit:\n\nPosit is a relatively new cloud service provider that focuses on offering high-performance computing resources specifically for data-intensive applications.\nThey provide bare-metal instances that ensure superior performance and flexibility.\nPosit is dedicated to data security and compliance, prioritizing the protection of user data.\nThey offer customizable hardware configurations tailored to meet specific application requirements.\n\nAWS:\n\nAWS is a well-established cloud service provider that offers a wide range of cloud computing services, including computing, storage, and database services.\nIt boasts a large and active user community, providing abundant resources and support for users.\nAWS provides flexible pricing options, including pay-as-you-go and reserved instance pricing.\nThey offer a comprehensive set of tools and services for managing and securing cloud-based applications.\n\nAzure:\n\nAzure is another leading cloud service provider that offers various cloud computing services, including computing, storage, and networking.\nIt tightly integrates with Microsoft’s enterprise software and services, making it an attractive option for organizations using Microsoft technologies.\nAzure provides flexible pricing models, including pay-as-you-go, reserved instance, and spot instance pricing.\nThey offer a wide array of tools and services for managing and securing cloud-based applications.\n\nGCP:\n\nGCP is a cloud service provider that provides a comprehensive suite of cloud computing services, including computing, storage, and networking.\nIt offers specialized tools and services for machine learning and artificial intelligence applications.\nGCP provides flexible pricing options, including pay-as-you-go and sustained use pricing.\nThey offer a range of tools and services for managing and securing cloud-based applications. [7]"
  },
  {
    "objectID": "01OverviewOfR.html#references",
    "href": "01OverviewOfR.html#references",
    "title": "Getting Started",
    "section": "",
    "text": "[1] Chambers, J. M. (2016). Extending R (2nd ed.). CRC Press.\nGandrud, C. (2015). Reproducible research with R and RStudio. CRC Press.\nGrolemund, G., & Wickham, H. (2017). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media.\nIhaka, R., & Gentleman, R. (1996). R: A language for data analysis and graphics. Journal of Computational and Graphical Statistics, 5(3), 299-314. https://www.jstor.org/stable/1390807\nMurrell, P. (2006). R graphics. CRC Press.\nPeng, R. D. (2016). R programming for data science. O’Reilly Media.\nR Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/\nVenables, W. N., Smith, D. M., & R Development Core Team. (2019). An introduction to R. Network Theory Ltd. Retrieved from https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf\nWickham, H. (2014). Tidy data. Journal of Statistical Software, 59(10), 1-23.\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag.\nWickham, H., & Grolemund, G. (2017). R packages: Organize, test, document, and share your code. O’Reilly Media.\n[2] The R Project for Statistical Computing. (2021). Download R for (Mac) OS X. https://cran.r-project.org/bin/macosx/\nThe R Project for Statistical Computing. (2021). Download R for Windows. https://cran.r-project.org/bin/windows/base/\nThe R Project for Statistical Computing. (2021). Download R for Linux. https://cran.r-project.org/bin/linux/\n[3] Grant, E., & Allen, B. (2021). Integrated Development Environments: A Comprehensive Overview. Journal of Software Engineering, 16(3), 123-145. doi:10./jswe.2021.16.3.123\nJohnson, M. L., & Smith, R. W. (2022). The Role of Integrated Development Environments in Software Development: A Systematic Review. ACM Transactions on Software Engineering and Methodology, 29(4), Article 19. doi:10./tosem.2022.29.4.19\nRStudio, PBC. (n.d.). RStudio: Open source and enterprise-ready professional software for R. Retrieved July 3, 2023, from https://www.rstudio.com/\nMicrosoft. (n.d.). Visual Studio Code: Code Editing. Redefined. Retrieved July 3, 2023, from https://code.visualstudio.com/\nProject Jupyter. (n.d.). Jupyter: Open-source, interactive data science and scientific computing across over 40 programming languages. Retrieved July 3, 2023, from https://jupyter.org/\n[4] RStudio. (2021). RStudio. https://www.rstudio.com/\nRStudio. (2021). RStudio. https://www.rstudio.com/products/rstudio/features/\n[5] RStudio. (2021). RStudio. https://www.rstudio.com/products/rstudio/download/\n[6] Armbrust, M., Fox, A., Griffith, R., Joseph, A. D., Katz, R., Konwinski, A., … Zaharia, M. (2010). A view of cloud computing. Communications of the ACM, 53(4), 50–58. https://doi.org/10.1145/1721654.1721672\nXiao, Z., Chen, Z., & Zhang, J. (2014). Cloud computing research and security issues. Journal of Network and Computer Applications, 41, 1–11. https://doi.org/10.1016/j.jnca.2013.11.004\nCloud Spectator. (2021). Cloud Service Provider Pricing Models: A Comprehensive Guide. https://www.cloudspectator.com/cloud-service-provider-pricing-models-a-comprehensive-guide/\n[7] Amazon Web Services. (2021). AWS. https://aws.amazon.com/\nAmazon Web Services. (2021). Running RStudio Server Pro using Amazon EC2. https://docs.rstudio.com/rsp/quickstart/aws/\nAmazon Web Services. (2021). EC2 User Guide for Linux Instances. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html\nGoogle Cloud Platform. (2021). GCP. https://cloud.google.com/\nGoogle Cloud Platform. (2021). Compute Engine Documentation. https://cloud.google.com/compute/docs\nMicrosoft Azure. (2021). Azure. https://azure.microsoft.com/\nMicrosoft Azure. (2021). Create a Windows virtual machine with the Azure portal. https://docs.microsoft.com/en-us/azure/virtual-machines/windows/quick-create-portal\nPosit. (2021). High-Performance Computing Services. https://posit.cloud/"
  },
  {
    "objectID": "05ReadingData.html",
    "href": "05ReadingData.html",
    "title": "Reading Data",
    "section": "",
    "text": "Dataframes and Tibbles are frequently employed data structures in R for storing and manipulating data. They facilitate the organization, exploration, and analysis of data.\n\n\n\nA dataframe is a two-dimensional table-like data structure in R that stores data in rows and columns, with distinct data types for each column.\nSimilar to a spreadsheet or a SQL table, it is one of the most frequently employed data structures in R. Each column in a data.frame is a constant-length vector, and each row represents an observation or case.\nUsing the data.frame() function or by importing data from external sources such as CSV files, Excel spreadsheets, or databases, dataframe objects can be created in R.\ndataframe objects have many useful built-in methods and functions for manipulating and summarizing data, including subsetting, merging, filtering, and aggregation. [1]\n\n\n\n\nThe following code generates a data.frame named df containing three columns - names, ages, and heights, and four rows of data for each individual.\n\n\n# Create input data as vectors\nnames &lt;- c(\"Ashok\", \"Bullu\", \"Charu\", \"Divya\")\nages &lt;- c(72, 49, 46, 42)\nheights &lt;- c(170, 167, 160, 166)\n\n# Combine input data into a data.frame\npeople &lt;- data.frame(Name = names, Age = ages, Height = heights)\n\n# Print the resulting dataframe\nprint(people)\n\n   Name Age Height\n1 Ashok  72    170\n2 Bullu  49    167\n3 Charu  46    160\n4 Divya  42    166\n\n\n\n\n\n\n\nR contains a number of built-in datasets that can be accessed without downloading or integrating from external sources. Here are some of the most frequently used built-in datasets in R:\n\n\nwomen: This dataset includes the heights and weights of a sample of 15,000 women.\nmtcars: This dataset contains information on 32 distinct automobile models, including the number of cylinders, engine displacement, horsepower, and weight.\ndiamonds: This dataset includes the prices and characteristics of approximately 54,000 diamonds, including carat weight, cut, color, and clarity.\niris: This data set measures the sepal length, sepal width, petal length, and petal breadth of 150 iris flowers from three distinct species.\n\n\n\nAs an illustration, consider the women dataset inbuilt in R, which contains information about the heights and weights of women. It has just two variables:\n\nheight: Height of each woman in inches\nweight: Weight of each woman in pounds\nThe data() function is used to import any inbuilt dataset into R. The data(women) command in R loads the women dataset\n\n\ndata(women)\n\n\nThe str() function gives the dimensions and data types and also previews the data.\n\n\nstr(women)\n\n'data.frame':   15 obs. of  2 variables:\n $ height: num  58 59 60 61 62 63 64 65 66 67 ...\n $ weight: num  115 117 120 123 126 129 132 135 139 142 ...\n\n\n\nThe summary() function gives some summary statistics.\n\n\nsummary(women)\n\n     height         weight     \n Min.   :58.0   Min.   :115.0  \n 1st Qu.:61.5   1st Qu.:124.5  \n Median :65.0   Median :135.0  \n Mean   :65.0   Mean   :136.7  \n 3rd Qu.:68.5   3rd Qu.:148.0  \n Max.   :72.0   Max.   :164.0  \n\n\n\n\n\nThe mtcars dataset inbuilt in R comprises data on the fuel consumption and other characteristics of 32 different automobile models. Here is a concise description of the 11 mtcars data columns:\n\nmpg: Miles per gallon (fuel efficiency)\ncyl: Number of cylinders\ndisp: Displacement of the engine (in cubic inches)\nhp: gross horsepower\ndrat: Back axle ratio wt: Weight (in thousands of pounds)\nwt: Weight (in thousands of pounds)\nqsec: 1/4 mile speed (in seconds)\nvs: Type of engine (0 = V-shaped, 1 = straight)\nam: Type of transmission (0 for automatic, 1 for manual)\ngear: the number of forward gears\ncarb: the number of carburetors\n\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n\n\n\n\n\n\nWe examine how to read data into a dataframe in R when the original data is stored in prominent file formats such as CSV, Excel, and Google Sheets.\nBefore learning how to accomplish this, it is necessary to comprehend how to configure the Working Directory in R.\n\n\n\n\nThe working directory is the location where R searches for and saves files by default.\nBy default, when we execute a script or import data into R, R will search the working directory for files.\nUsing R’s getwd() function, we can examine our current working directory:\n\n\ngetwd()\n\n[1] \"/cloud/project\"\n\n\n\nWe are running R in the Cloud and hence we are seeing that the working directory is specified as /cloud/project/DataAnalyticsBook101. If we are doing R programming on a local computer, and if our working directory is the Desktop, then we may see a different response such as C:/Users/YourUserName/Desktop.\nUsing R’s setwd() function, we can change our current working directory. For example, the following code will set our working directory to the Desktop:\n\n\nsetwd(\"C:/Users/YourUserName/Desktop\")\n\n\nWe should choose an easily-remembered and accessible working directory to store our R scripts and data files. Additionally, we should avoid using spaces, special characters, and non-ASCII characters in file paths, as these can cause file handling issues in R. [2]\n\n\n\n\n\nCSV is the abbreviation for “Comma-Separated Values.” A CSV file is a plain text file that stores structured tabular data.\nEach entry in a CSV file represents a record, whereas each column represents a field. The elements in each record are separated by commas (hence the name Comma-Separated Values), semicolons, or tabs.\nBefore proceeding ahead, it is imperative that the file that we wish to read is located in the Working Directory.\nSuppose we wish to import a CSV file named mtcars.csv, located in the Working Directory. We can use the read.csv() function, illustrated as follows.\n\n\ndf_csv &lt;- read.csv(\"mtcars.csv\")\n\n\nIn this example, the read.csv() function reads the mtcars.csv file into a data frame named df_csv.\nIf the file is not in the current working directory, the complete file path must be specified in the read.csv() function argument; otherwise, an error will occur.\n\n\n\n\n\nSuppose we wish to import a Microsoft Excel file named mtcars.xlsx, located in the Working Directory.\nWe can use the read_excel function in the R package readxl, illustrated as follows.\n\n\nlibrary(readxl)\ndf_xlsx &lt;- read_excel(\"mtcars.xlsx\")\n\n\n\n\n\nGoogle Sheets is a ubiquitous cloud-based spreadsheet application developed by Google. It is a web-based application that enables collaborative online creation and modification of spreadsheets.\nWe can import data from a Google Sheet into a R dataframe, as follows.\n\n\nConsider a Google Sheet whose preferences have been set such that anyone can view it using its URL. If this is not done, then some authentication would become necessary.\nEvery Google Sheet is characterized by a unique Sheet ID, embedded within the URL. For example, consider a Google Sheet containing some financial data concerning S&P500 index shares.\nSuppose the Sheet ID is: 1nm688a3GsPM5cadJIwu6zj336WBaduglY9TSTUaM9jk\nWe can use the function gsheet2tbl in package gsheet to read the Google Sheet into a dataframe, as demonstrated in the following code.\n\n\n# Read recent S&P500 data that is posted in a Google Sheet.\nlibrary(gsheet)\n\nprefix &lt;- \"https://docs.google.com/spreadsheets/d/\"\nsheetID &lt;- \"1nm688a3GsPM5cadJIwu6zj336WBaduglY9TSTUaM9jk\"\nsuffix &lt;- \"/edit#gid=0\"\n\n# Form the URL to connect to\nurl &lt;- paste(prefix, sheetID, suffix) \n\n# Read the Google Sheet located at the URL into a dataframe called gf\ngf &lt;- gsheet2tbl(url)\n\nNo encoding supplied: defaulting to UTF-8.\n\n\n\nThe first line imports the gsheet package required to access Google Sheets into R.\nThe following three lines define URL variables for Google Sheets. The prefix variable contains the base URL for accessing Google Sheets, the sheetID variable contains the ID of the desired Google Sheet, and the suffix variable contains the URL’s suffix.\nThe paste() function is used to combine the prefix, sheetID, and suffix variables into a complete URL for accessing the Google Sheet.\nThe gsheet2tbl() function from the gsheet package is then used to read the specified Google Sheet into a dataframe called gf.\nOnce the preceding code is executed, the gf dataframe will contain the Google Sheet data, which can then be analyzed further in R.\n\n\n\n\n\nSuppose we have a second S&P 500 data located in a second Google Sheet and suppose that we would like to join or merge the data in this dataframe with the above dataframe gf.\nThe ID of this second sheet is: 1F5KvFATcehrdJuGjYVqppNYC9hEKSww9rXYHCk2g6OA\nWe can read the data present in this Google Sheet using the following code, similar to the one discussed above, using the following code.\n\n\n# Read additional S&P500 data presend in another Google Sheet.\nlibrary(gsheet)\n\nprefix &lt;- \"https://docs.google.com/spreadsheets/d/\"\nsheetID &lt;- \"1F5KvFATcehrdJuGjYVqppNYC9hEKSww9rXYHCk2g6OA\"\nsuffix &lt;- \"/edit#gid=0\"\n\n# Form the URL to connect to\nurl &lt;- paste(prefix, sheetID, suffix) \n\n# Read the Google Sheet located at the URL into a dataframe called tv\ntv &lt;- gsheet2tbl(url)\n\nNo encoding supplied: defaulting to UTF-8.\n\n\n\nWe now have two dataframes named tv and gf that we wish to merge or join.\nThe two dataframes have a column named Stock in common, which will serve as the key.\nThe following code illusrates how to merge two dataframes:\n\n\n# merging dataframes\nM.df &lt;- merge(tv, gf , id = \"Stock\")\n\n\nWe now have a new dataframe named M.df, which contains the data got from merging the two dataframes tv and gf.\n\n\n\n\n\n\nA tibble is a contemporary and enhanced variant of a R data frame that is part of the tidyverse package collection.\nTibbles are created and manipulated using the dplyr package, which provides a suite of functions optimized for data manipulation.\nThe following characteristics distinguish a tibble from a conventional data frame:\nTibbles must always have unique, non-empty column names. Tibbles do not permit the creation or modification of columns using partial matching of column names. Tibbles improve the output of large datasets by displaying by default only a few rows and columns.\nTibbles have a more consistent behavior for subsetting, with the use of [[ always returning a vector or NULL, and [] always returning a tibble.\nHere is an example of using the tibble() function in dplyr to construct a tibble:\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Create a tibble\nmy_tibble &lt;- tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  age = c(25, 30, 35),\n  gender = c(\"F\", \"M\", \"M\")\n)\n\n# Print the tibble\nmy_tibble\n\n# A tibble: 3 × 3\n  name      age gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 Alice      25 F     \n2 Bob        30 M     \n3 Charlie    35 M     \n\n\n\nThis will generate a tibble consisting of three columns (name, age, and gender) and three rows of data. Note that the column names are preserved and the tibble is printed in a compact and legible manner.\n\n\n\n\n# Create a data frame\nmy_df &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  age = c(25, 30, 35),\n  gender = c(\"F\", \"M\", \"M\")\n)\n\n# Convert the data frame to a tibble\nmy_tibble &lt;- as_tibble(my_df)\n\n# Print the tibble\nmy_tibble\n\n# A tibble: 3 × 3\n  name      age gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 Alice      25 F     \n2 Bob        30 M     \n3 Charlie    35 M     \n\n\n\nThis assigns the tibble representation of the data frame my_df to the variable my_tibble.\nNote that the resulting tibble has the same column names and data as the original data frame, but has the additional characteristics and behaviors of a tibble.\n\n\n\n\n\nlibrary(dplyr)\n\n# Convert the tibble to a data frame\nmy_df &lt;- as.data.frame(my_tibble)\n\n# Print the data frame\nmy_df\n\n     name age gender\n1   Alice  25      F\n2     Bob  30      M\n3 Charlie  35      M\n\n\n\nA tibble offers several advantages over a data frame in R:\n\n\nLarge datasets can be printed with greater clarity and precision using Tibbles. By default, they only print the first few rows and columns, making it simpler to read and comprehend the data structure.\nBetter subsetting behavior: With [[always returning a vector or NULL and [] always returning a tibble, Tibbles have a more consistent subsetting behavior. This facilitates the subset and manipulation of data without unintended consequences.\nConsistent naming: Tibbles always have column names that are distinct and non-empty. This makes it simpler to refer to specific columns and prevents errors caused by duplicate or unnamed column names.\nMore informative errors: Tibbles provides more informative error messages that make it simpler to diagnose and resolve data-related problems.\nFewer surprises: Tibbles have more stringent constraints than data frames, resulting in fewer surprises and unexpected behavior when manipulating data.\n\n\n\n\n\n[1]\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\nR Core Team. (2022). Vectors, Lists, and Arrays. R Documentation. https://cran.r-project.org/doc/manuals/r-release/R-intro.html#vectors-lists-and-arrays\nWickham, H., & Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media, Inc.\nR Core Team. (2022, March 2). Data Frames. R Documentation. https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/data.frame\n[2]\nOpenIntro. (2022). 1.3 RStudio and working directory. In Introductory Statistics with Randomization and Simulation (1st ed.). https://www.openintro.org/book/isrs/\nR Core Team. (2021). getwd(): working directory; setwd(dir): change working directory. In R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://stat.ethz.ch/R-manual/R-devel/library/base/html/getwd.html\nR Core Team. (2021). getwd(): working directory; setwd(dir): change working directory. In R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://stat.ethz.ch/R-manual/R-devel/library/base/html/setwd.html"
  },
  {
    "objectID": "05ReadingData.html#dataframes",
    "href": "05ReadingData.html#dataframes",
    "title": "Reading Data",
    "section": "",
    "text": "A dataframe is a two-dimensional table-like data structure in R that stores data in rows and columns, with distinct data types for each column.\nSimilar to a spreadsheet or a SQL table, it is one of the most frequently employed data structures in R. Each column in a data.frame is a constant-length vector, and each row represents an observation or case.\nUsing the data.frame() function or by importing data from external sources such as CSV files, Excel spreadsheets, or databases, dataframe objects can be created in R.\ndataframe objects have many useful built-in methods and functions for manipulating and summarizing data, including subsetting, merging, filtering, and aggregation. [1]\n\n\n\n\nThe following code generates a data.frame named df containing three columns - names, ages, and heights, and four rows of data for each individual.\n\n\n# Create input data as vectors\nnames &lt;- c(\"Ashok\", \"Bullu\", \"Charu\", \"Divya\")\nages &lt;- c(72, 49, 46, 42)\nheights &lt;- c(170, 167, 160, 166)\n\n# Combine input data into a data.frame\npeople &lt;- data.frame(Name = names, Age = ages, Height = heights)\n\n# Print the resulting dataframe\nprint(people)\n\n   Name Age Height\n1 Ashok  72    170\n2 Bullu  49    167\n3 Charu  46    160\n4 Divya  42    166"
  },
  {
    "objectID": "05ReadingData.html#reading-inbuilt-datasets-in-r",
    "href": "05ReadingData.html#reading-inbuilt-datasets-in-r",
    "title": "Reading Data",
    "section": "",
    "text": "R contains a number of built-in datasets that can be accessed without downloading or integrating from external sources. Here are some of the most frequently used built-in datasets in R:\n\n\nwomen: This dataset includes the heights and weights of a sample of 15,000 women.\nmtcars: This dataset contains information on 32 distinct automobile models, including the number of cylinders, engine displacement, horsepower, and weight.\ndiamonds: This dataset includes the prices and characteristics of approximately 54,000 diamonds, including carat weight, cut, color, and clarity.\niris: This data set measures the sepal length, sepal width, petal length, and petal breadth of 150 iris flowers from three distinct species.\n\n\n\nAs an illustration, consider the women dataset inbuilt in R, which contains information about the heights and weights of women. It has just two variables:\n\nheight: Height of each woman in inches\nweight: Weight of each woman in pounds\nThe data() function is used to import any inbuilt dataset into R. The data(women) command in R loads the women dataset\n\n\ndata(women)\n\n\nThe str() function gives the dimensions and data types and also previews the data.\n\n\nstr(women)\n\n'data.frame':   15 obs. of  2 variables:\n $ height: num  58 59 60 61 62 63 64 65 66 67 ...\n $ weight: num  115 117 120 123 126 129 132 135 139 142 ...\n\n\n\nThe summary() function gives some summary statistics.\n\n\nsummary(women)\n\n     height         weight     \n Min.   :58.0   Min.   :115.0  \n 1st Qu.:61.5   1st Qu.:124.5  \n Median :65.0   Median :135.0  \n Mean   :65.0   Mean   :136.7  \n 3rd Qu.:68.5   3rd Qu.:148.0  \n Max.   :72.0   Max.   :164.0  \n\n\n\n\n\nThe mtcars dataset inbuilt in R comprises data on the fuel consumption and other characteristics of 32 different automobile models. Here is a concise description of the 11 mtcars data columns:\n\nmpg: Miles per gallon (fuel efficiency)\ncyl: Number of cylinders\ndisp: Displacement of the engine (in cubic inches)\nhp: gross horsepower\ndrat: Back axle ratio wt: Weight (in thousands of pounds)\nwt: Weight (in thousands of pounds)\nqsec: 1/4 mile speed (in seconds)\nvs: Type of engine (0 = V-shaped, 1 = straight)\nam: Type of transmission (0 for automatic, 1 for manual)\ngear: the number of forward gears\ncarb: the number of carburetors\n\n\ndata(mtcars)\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ..."
  },
  {
    "objectID": "05ReadingData.html#reading-different-file-formats-into-a-dataframe",
    "href": "05ReadingData.html#reading-different-file-formats-into-a-dataframe",
    "title": "Reading Data",
    "section": "",
    "text": "We examine how to read data into a dataframe in R when the original data is stored in prominent file formats such as CSV, Excel, and Google Sheets.\nBefore learning how to accomplish this, it is necessary to comprehend how to configure the Working Directory in R.\n\n\n\n\nThe working directory is the location where R searches for and saves files by default.\nBy default, when we execute a script or import data into R, R will search the working directory for files.\nUsing R’s getwd() function, we can examine our current working directory:\n\n\ngetwd()\n\n[1] \"/cloud/project\"\n\n\n\nWe are running R in the Cloud and hence we are seeing that the working directory is specified as /cloud/project/DataAnalyticsBook101. If we are doing R programming on a local computer, and if our working directory is the Desktop, then we may see a different response such as C:/Users/YourUserName/Desktop.\nUsing R’s setwd() function, we can change our current working directory. For example, the following code will set our working directory to the Desktop:\n\n\nsetwd(\"C:/Users/YourUserName/Desktop\")\n\n\nWe should choose an easily-remembered and accessible working directory to store our R scripts and data files. Additionally, we should avoid using spaces, special characters, and non-ASCII characters in file paths, as these can cause file handling issues in R. [2]\n\n\n\n\n\nCSV is the abbreviation for “Comma-Separated Values.” A CSV file is a plain text file that stores structured tabular data.\nEach entry in a CSV file represents a record, whereas each column represents a field. The elements in each record are separated by commas (hence the name Comma-Separated Values), semicolons, or tabs.\nBefore proceeding ahead, it is imperative that the file that we wish to read is located in the Working Directory.\nSuppose we wish to import a CSV file named mtcars.csv, located in the Working Directory. We can use the read.csv() function, illustrated as follows.\n\n\ndf_csv &lt;- read.csv(\"mtcars.csv\")\n\n\nIn this example, the read.csv() function reads the mtcars.csv file into a data frame named df_csv.\nIf the file is not in the current working directory, the complete file path must be specified in the read.csv() function argument; otherwise, an error will occur.\n\n\n\n\n\nSuppose we wish to import a Microsoft Excel file named mtcars.xlsx, located in the Working Directory.\nWe can use the read_excel function in the R package readxl, illustrated as follows.\n\n\nlibrary(readxl)\ndf_xlsx &lt;- read_excel(\"mtcars.xlsx\")\n\n\n\n\n\nGoogle Sheets is a ubiquitous cloud-based spreadsheet application developed by Google. It is a web-based application that enables collaborative online creation and modification of spreadsheets.\nWe can import data from a Google Sheet into a R dataframe, as follows.\n\n\nConsider a Google Sheet whose preferences have been set such that anyone can view it using its URL. If this is not done, then some authentication would become necessary.\nEvery Google Sheet is characterized by a unique Sheet ID, embedded within the URL. For example, consider a Google Sheet containing some financial data concerning S&P500 index shares.\nSuppose the Sheet ID is: 1nm688a3GsPM5cadJIwu6zj336WBaduglY9TSTUaM9jk\nWe can use the function gsheet2tbl in package gsheet to read the Google Sheet into a dataframe, as demonstrated in the following code.\n\n\n# Read recent S&P500 data that is posted in a Google Sheet.\nlibrary(gsheet)\n\nprefix &lt;- \"https://docs.google.com/spreadsheets/d/\"\nsheetID &lt;- \"1nm688a3GsPM5cadJIwu6zj336WBaduglY9TSTUaM9jk\"\nsuffix &lt;- \"/edit#gid=0\"\n\n# Form the URL to connect to\nurl &lt;- paste(prefix, sheetID, suffix) \n\n# Read the Google Sheet located at the URL into a dataframe called gf\ngf &lt;- gsheet2tbl(url)\n\nNo encoding supplied: defaulting to UTF-8.\n\n\n\nThe first line imports the gsheet package required to access Google Sheets into R.\nThe following three lines define URL variables for Google Sheets. The prefix variable contains the base URL for accessing Google Sheets, the sheetID variable contains the ID of the desired Google Sheet, and the suffix variable contains the URL’s suffix.\nThe paste() function is used to combine the prefix, sheetID, and suffix variables into a complete URL for accessing the Google Sheet.\nThe gsheet2tbl() function from the gsheet package is then used to read the specified Google Sheet into a dataframe called gf.\nOnce the preceding code is executed, the gf dataframe will contain the Google Sheet data, which can then be analyzed further in R.\n\n\n\n\n\nSuppose we have a second S&P 500 data located in a second Google Sheet and suppose that we would like to join or merge the data in this dataframe with the above dataframe gf.\nThe ID of this second sheet is: 1F5KvFATcehrdJuGjYVqppNYC9hEKSww9rXYHCk2g6OA\nWe can read the data present in this Google Sheet using the following code, similar to the one discussed above, using the following code.\n\n\n# Read additional S&P500 data presend in another Google Sheet.\nlibrary(gsheet)\n\nprefix &lt;- \"https://docs.google.com/spreadsheets/d/\"\nsheetID &lt;- \"1F5KvFATcehrdJuGjYVqppNYC9hEKSww9rXYHCk2g6OA\"\nsuffix &lt;- \"/edit#gid=0\"\n\n# Form the URL to connect to\nurl &lt;- paste(prefix, sheetID, suffix) \n\n# Read the Google Sheet located at the URL into a dataframe called tv\ntv &lt;- gsheet2tbl(url)\n\nNo encoding supplied: defaulting to UTF-8.\n\n\n\nWe now have two dataframes named tv and gf that we wish to merge or join.\nThe two dataframes have a column named Stock in common, which will serve as the key.\nThe following code illusrates how to merge two dataframes:\n\n\n# merging dataframes\nM.df &lt;- merge(tv, gf , id = \"Stock\")\n\n\nWe now have a new dataframe named M.df, which contains the data got from merging the two dataframes tv and gf."
  },
  {
    "objectID": "05ReadingData.html#tibbles",
    "href": "05ReadingData.html#tibbles",
    "title": "Reading Data",
    "section": "",
    "text": "A tibble is a contemporary and enhanced variant of a R data frame that is part of the tidyverse package collection.\nTibbles are created and manipulated using the dplyr package, which provides a suite of functions optimized for data manipulation.\nThe following characteristics distinguish a tibble from a conventional data frame:\nTibbles must always have unique, non-empty column names. Tibbles do not permit the creation or modification of columns using partial matching of column names. Tibbles improve the output of large datasets by displaying by default only a few rows and columns.\nTibbles have a more consistent behavior for subsetting, with the use of [[ always returning a vector or NULL, and [] always returning a tibble.\nHere is an example of using the tibble() function in dplyr to construct a tibble:\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Create a tibble\nmy_tibble &lt;- tibble(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  age = c(25, 30, 35),\n  gender = c(\"F\", \"M\", \"M\")\n)\n\n# Print the tibble\nmy_tibble\n\n# A tibble: 3 × 3\n  name      age gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 Alice      25 F     \n2 Bob        30 M     \n3 Charlie    35 M     \n\n\n\nThis will generate a tibble consisting of three columns (name, age, and gender) and three rows of data. Note that the column names are preserved and the tibble is printed in a compact and legible manner.\n\n\n\n\n# Create a data frame\nmy_df &lt;- data.frame(\n  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n  age = c(25, 30, 35),\n  gender = c(\"F\", \"M\", \"M\")\n)\n\n# Convert the data frame to a tibble\nmy_tibble &lt;- as_tibble(my_df)\n\n# Print the tibble\nmy_tibble\n\n# A tibble: 3 × 3\n  name      age gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 Alice      25 F     \n2 Bob        30 M     \n3 Charlie    35 M     \n\n\n\nThis assigns the tibble representation of the data frame my_df to the variable my_tibble.\nNote that the resulting tibble has the same column names and data as the original data frame, but has the additional characteristics and behaviors of a tibble.\n\n\n\n\n\nlibrary(dplyr)\n\n# Convert the tibble to a data frame\nmy_df &lt;- as.data.frame(my_tibble)\n\n# Print the data frame\nmy_df\n\n     name age gender\n1   Alice  25      F\n2     Bob  30      M\n3 Charlie  35      M\n\n\n\nA tibble offers several advantages over a data frame in R:\n\n\nLarge datasets can be printed with greater clarity and precision using Tibbles. By default, they only print the first few rows and columns, making it simpler to read and comprehend the data structure.\nBetter subsetting behavior: With [[always returning a vector or NULL and [] always returning a tibble, Tibbles have a more consistent subsetting behavior. This facilitates the subset and manipulation of data without unintended consequences.\nConsistent naming: Tibbles always have column names that are distinct and non-empty. This makes it simpler to refer to specific columns and prevents errors caused by duplicate or unnamed column names.\nMore informative errors: Tibbles provides more informative error messages that make it simpler to diagnose and resolve data-related problems.\nFewer surprises: Tibbles have more stringent constraints than data frames, resulting in fewer surprises and unexpected behavior when manipulating data."
  },
  {
    "objectID": "05ReadingData.html#references",
    "href": "05ReadingData.html#references",
    "title": "Reading Data",
    "section": "",
    "text": "[1]\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\nR Core Team. (2022). Vectors, Lists, and Arrays. R Documentation. https://cran.r-project.org/doc/manuals/r-release/R-intro.html#vectors-lists-and-arrays\nWickham, H., & Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media, Inc.\nR Core Team. (2022, March 2). Data Frames. R Documentation. https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/data.frame\n[2]\nOpenIntro. (2022). 1.3 RStudio and working directory. In Introductory Statistics with Randomization and Simulation (1st ed.). https://www.openintro.org/book/isrs/\nR Core Team. (2021). getwd(): working directory; setwd(dir): change working directory. In R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://stat.ethz.ch/R-manual/R-devel/library/base/html/getwd.html\nR Core Team. (2021). getwd(): working directory; setwd(dir): change working directory. In R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://stat.ethz.ch/R-manual/R-devel/library/base/html/setwd.html"
  },
  {
    "objectID": "03InbuiltRFunctions.html",
    "href": "03InbuiltRFunctions.html",
    "title": "Inbuilt R functions",
    "section": "",
    "text": "R is a powerful programming language for performing mathematical operations and statistical calculations. Here are some common mathematical operations in R.\n\nArithmetic Operations: R can perform basic arithmetic operations such as addition (+), subtraction (-), multiplication (*), and division (/).\n\n\n# Addition and Subtraction\n5+9-3\n\n[1] 11\n\n# Multiplication and Division\n(5 + 3) * 7 /2\n\n[1] 28\n\n\n\nExponentiation and Logarithms: R can raise a number to a power using the ^ or ** operator or take logarithms.\n\n\n# exponentiation\n2^6\n\n[1] 64\n\n# Exponential of x=2 i.e. e^2\nexp(2) \n\n[1] 7.389056\n\n# logarithms base 2 and base 10\nlog2(64) + log10(100)\n\n[1] 8\n\n\n\nOther mathematical functions: R has many additional useful mathematical functions.\n\n\nWe can find the absolute value, square roots, remainder on division.\n\n\n# absolute value of x=-5\nabs(-9) \n\n[1] 9\n\n# square root of x=70\nsqrt(70)\n\n[1] 8.3666\n\n# remainder of the division of 11/3\n11 %% 3\n\n[1] 2\n\n\n\nWe can round numbers, find their floor, ceiling or up to a number of significant digits\n\n\n# Value of pi to 10 decimal places\npi = 3.1415926536\n\n# round(): This function rounds a number to the given number of decimal places\n# For example, round(pi, 3) returns 3.142\nround(pi,3)\n\n[1] 3.142\n\n# ceiling(): This function rounds a number up to the nearest integer. \n# For example, ceiling(pi) returns 4\nceiling(pi) \n\n[1] 4\n\n# floor(): This function rounds a number down to the nearest integer. \n# For example, floor(pi) returns 3.\nfloor(pi)\n\n[1] 3\n\n# signif(): This function rounds a number to a specified number of significant digits. \n# For example, signif(pi, 3) returns 3.14.\nsignif(pi,3)\n\n[1] 3.14\n\n\n\nStatistical calculations: R has many built-in functions for statistical calculations, such as mean, median, standard deviation, and correlation.\n\n\nx &lt;- c(0, 1, 1, 2, 3, 5, 8)   # create a vector of 7 Fibonacci numbers\nlength(x) # count how many numbers do we have\n\n[1] 7\n\nmean(x)   # calculate the mean\n\n[1] 2.857143\n\nmedian(x) # calculate the median\n\n[1] 2\n\nsd(x)     # calculate the standard deviation\n\n[1] 2.794553\n\ny &lt;- c(1, 2, 3, 4, 5, 6, 7) # create a new vector of positive integers\ncor(x,y)  # calculate the correlation between x and y\n\n[1] 0.938668\n\n\n\n\n\n\nA variable can be used to store a value. For example, the R code below will store the sales in a variable, say “sales”:\n\n\n# use the assignment operator &lt;-\nsales &lt;- 9\n# alternately, use =\nsales = 9\n\n\nIt is possible to use &lt;- or = for variable assignments.\nR is case-sensitive. This means that Sales is different from sales\nIt is possible to perform some operations with it.\n\n\n# multiply sales by 2\n2 * sales\n\n[1] 18\n\n\n\nWe can change the value stored in a variable\n\n\n# change the value\nsales &lt;- 15\n# display the revised sales\nsales\n\n[1] 15\n\n\n\nThe following R code creates two variables holding the sales and the price of a product and we can use them to compute the revenue.\n\n\n# sales\nsales &lt;- 5\n\n# price\nprice &lt;- 7\n\n# Calculate the revenue\nrevenue &lt;- price*sales\nrevenue\n\n[1] 35"
  },
  {
    "objectID": "03InbuiltRFunctions.html#mathematical-operations",
    "href": "03InbuiltRFunctions.html#mathematical-operations",
    "title": "Inbuilt R functions",
    "section": "",
    "text": "R is a powerful programming language for performing mathematical operations and statistical calculations. Here are some common mathematical operations in R.\n\nArithmetic Operations: R can perform basic arithmetic operations such as addition (+), subtraction (-), multiplication (*), and division (/).\n\n\n# Addition and Subtraction\n5+9-3\n\n[1] 11\n\n# Multiplication and Division\n(5 + 3) * 7 /2\n\n[1] 28\n\n\n\nExponentiation and Logarithms: R can raise a number to a power using the ^ or ** operator or take logarithms.\n\n\n# exponentiation\n2^6\n\n[1] 64\n\n# Exponential of x=2 i.e. e^2\nexp(2) \n\n[1] 7.389056\n\n# logarithms base 2 and base 10\nlog2(64) + log10(100)\n\n[1] 8\n\n\n\nOther mathematical functions: R has many additional useful mathematical functions.\n\n\nWe can find the absolute value, square roots, remainder on division.\n\n\n# absolute value of x=-5\nabs(-9) \n\n[1] 9\n\n# square root of x=70\nsqrt(70)\n\n[1] 8.3666\n\n# remainder of the division of 11/3\n11 %% 3\n\n[1] 2\n\n\n\nWe can round numbers, find their floor, ceiling or up to a number of significant digits\n\n\n# Value of pi to 10 decimal places\npi = 3.1415926536\n\n# round(): This function rounds a number to the given number of decimal places\n# For example, round(pi, 3) returns 3.142\nround(pi,3)\n\n[1] 3.142\n\n# ceiling(): This function rounds a number up to the nearest integer. \n# For example, ceiling(pi) returns 4\nceiling(pi) \n\n[1] 4\n\n# floor(): This function rounds a number down to the nearest integer. \n# For example, floor(pi) returns 3.\nfloor(pi)\n\n[1] 3\n\n# signif(): This function rounds a number to a specified number of significant digits. \n# For example, signif(pi, 3) returns 3.14.\nsignif(pi,3)\n\n[1] 3.14\n\n\n\nStatistical calculations: R has many built-in functions for statistical calculations, such as mean, median, standard deviation, and correlation.\n\n\nx &lt;- c(0, 1, 1, 2, 3, 5, 8)   # create a vector of 7 Fibonacci numbers\nlength(x) # count how many numbers do we have\n\n[1] 7\n\nmean(x)   # calculate the mean\n\n[1] 2.857143\n\nmedian(x) # calculate the median\n\n[1] 2\n\nsd(x)     # calculate the standard deviation\n\n[1] 2.794553\n\ny &lt;- c(1, 2, 3, 4, 5, 6, 7) # create a new vector of positive integers\ncor(x,y)  # calculate the correlation between x and y\n\n[1] 0.938668"
  },
  {
    "objectID": "03InbuiltRFunctions.html#assigning-values-to-variables",
    "href": "03InbuiltRFunctions.html#assigning-values-to-variables",
    "title": "Inbuilt R functions",
    "section": "",
    "text": "A variable can be used to store a value. For example, the R code below will store the sales in a variable, say “sales”:\n\n\n# use the assignment operator &lt;-\nsales &lt;- 9\n# alternately, use =\nsales = 9\n\n\nIt is possible to use &lt;- or = for variable assignments.\nR is case-sensitive. This means that Sales is different from sales\nIt is possible to perform some operations with it.\n\n\n# multiply sales by 2\n2 * sales\n\n[1] 18\n\n\n\nWe can change the value stored in a variable\n\n\n# change the value\nsales &lt;- 15\n# display the revised sales\nsales\n\n[1] 15\n\n\n\nThe following R code creates two variables holding the sales and the price of a product and we can use them to compute the revenue.\n\n\n# sales\nsales &lt;- 5\n\n# price\nprice &lt;- 7\n\n# Calculate the revenue\nrevenue &lt;- price*sales\nrevenue\n\n[1] 35"
  },
  {
    "objectID": "04DataStructures.html",
    "href": "04DataStructures.html",
    "title": "Data Structures",
    "section": "",
    "text": "The R programming language includes a number of data structures that are frequently employed in data analysis and statistical modeling. These are some of the most popular data structures in R:\n\nVector: A vector is a one-dimensional array that stores identical data types, such as numeric, character, or logical. The “c()” function can be used to create vectors, and indexing can be used to access individual vector elements.\nFactor: A factor is a vector representing categorical data, with each distinct value or category represented as a level. Using indexing, individual levels of a factor can be accessed using the “factor()” function.\nDataframe: Similar to a spreadsheet, a data frame is a two-dimensional table-like structure that can store various types of data in columns. The “data.frame()” function can be used to construct data frames, and individual elements can be accessed using row and column indexing.\nMatrix: A matrix is a two-dimensional array of data with identical rows and columns. The “matrix()” function can be used to construct matrices, and individual elements can be accessed using row and column indexing.\nArray: An array is a multidimensional data structure that can contain data of the same data type in user-specified dimensions. Arrays can be constructed using the “array()” function, and elements can be accessed using multiple indexing.\nList: A list is an object that may comprise elements of various data types, including vectors, matrices, data frames, and even other lists. The “list()” function can be used to construct lists, while indexing can be used to access individual elements.\n\nThese data structures are helpful for storing and manipulating data in R, and they can be utilized in numerous applications, such as statistical analysis and data visualization.\nWe will focus our attention on Vectors, Factors and Dataframes, since we believe that these are the three most useful data structures. [1]\n\n\n\n\nA vector is a fundamental data structure in R that can hold a sequence of values of the same data type, such as integers, numeric, character, or logical values.\nA vector can be created using the c() function.\nR supports two forms of vectors: atomic vectors and lists. Atomic vectors are limited to containing elements of a single data type, such as numeric or character. Lists, on the other hand, can contain elements of various data types and structures. [1]\n\n\n\n\nThe following R code creates a numeric vector, a character vector and a logical vector respectively.\n\n\n# Read data into vectors\nnames &lt;- c(\"Ashok\", \"Bullu\", \"Charu\", \"Divya\")\nages &lt;- c(72, 49, 46, 42)\nfemales &lt;- c(FALSE, TRUE, TRUE, TRUE)\n\n\nThe c() function is employed to combine the four character elements into a single vector.\nCommas separate the elements of the vector within the parentheses.\nIndividual elements of the vector can be accessed via indexing, which utilizes square brackets []. For instance, names[1] returns “Ashok”, while names[3] returns “Charu”.\nWe can also perform operations such as categorizing and filtering on the entire vector. For instance, sort(names) returns a vector of sorted names, whereas names[names!= “Bullu”] returns a vector of names excluding “Bullu.”\n\n\n\n\nVectors can be used to perform the following vector operations:\n\nAccessing Elements: We can use indexing with square brackets to access individual elements of a vector. To access the second element of the “names” vector, for instance, we can use:\n\n\nnames[2]\n\n[1] \"Bullu\"\n\n\nThis returns “Bullu”, the second element of the “names” vector.\n\nConcatenation: The “c()” function can be used to combine multiple vectors into a single vector. For instance, to combine the “names” and “ages” vectors into the “people” vector, we can use:\n\n\npersons &lt;- c(names, ages)\npersons\n\n[1] \"Ashok\" \"Bullu\" \"Charu\" \"Divya\" \"72\"    \"49\"    \"46\"    \"42\"   \n\n\nThis generates an eight-element vector containing the names and ages of the four people.\n\nSubsetting: We can use indexing with a logical condition to construct a new vector that contains a subset of elements from an existing vector. For instance, to construct a new vector named “female_names” containing only the females’ names, we can use:\n\n\nfemale_names &lt;- names[females == TRUE]\nfemale_names\n\n[1] \"Bullu\" \"Charu\" \"Divya\"\n\n\nThis generates a new vector comprising three elements containing the names of the three females (“Bullu”, “Charu”, and “Divya”).\n\nArithmetic Operations: We can perform element-wise arithmetic operations on vectors. To calculate the sum of the “ages” vector, for instance, we can use:\n\n\nsum(ages)\n\n[1] 209\n\n\nThis returns 209, the sum of the four ages.\n\nLogical Operations: We can perform logical operations on vectors, which are also executed element-by-element. To create a new vector titled “middle_age” that indicates whether each individual is 45 to 55 years old, for instance, we can use:\n\n\nmiddle_age &lt;- (ages &gt;= 45) & (ages &lt;= 55)\nmiddle_age\n\n[1] FALSE  TRUE  TRUE FALSE\n\n\nThis generates a new vector with four elements containing logical values indicating whether each person is between 45 and 55 years of age.\nTo test whether any of the elements in the “ages” vector are greater than 50, we can use:\n\nany(ages &gt; 50)\n\n[1] TRUE\n\n\n\nUnique Values: We can find the unique values in a vector using the “unique()” function. For example, to find the unique values in the “ages” vector, we can use:\n\n\nunique(ages)\n\n[1] 72 49 46 42\n\n\n\nSorting: We can sort a vector in ascending or descending order using the “sort()” function. For example, to sort the “ages” vector in descending order, we can use:\n\n\nsort(ages, decreasing = TRUE)\n\n[1] 72 49 46 42\n\n\n\n\n\n\nLength: The length represents the count of the number of elements in a vector.\n\n\nlength(ages)\n\n[1] 4\n\n\n\nMaximum and Minimum: The maximum and minimum values are the vector’s greatest and smallest values, respectively.\nRange: The range is a measure of the spread that represents the difference between the maximum and minimum values in a vector.\n\n\nmin(ages)\n\n[1] 42\n\nmax(ages)\n\n[1] 72\n\nrange(ages)\n\n[1] 42 72\n\n\n\nMean: The mean is a central tendency measure that represents the average value of a vector’s elements.\nStandard Deviation: The standard deviation is a measure of dispersion that reflects the amount of variation in a vector’s elements.\nVariance: The variance is another measure of the spread. It is square of the Standard Deviation.\n\n\nmean(ages)\n\n[1] 52.25\n\nsd(ages)\n\n[1] 13.47529\n\nvar(ages)\n\n[1] 181.5833\n\n\n\nMedian: The median is a measure of central tendency that represents the middle value of a sorted vector.\n\n\nmedian(ages)\n\n[1] 47.5\n\n\n\nQuantiles: The quantiles are a set of cut-off points that divide a sorted vector into equal-sized groups.\n\n\nquantile(ages)\n\n   0%   25%   50%   75%  100% \n42.00 45.00 47.50 54.75 72.00 \n\n\nThis will return a set of five values, representing the minimum, first quartile, median, third quartile, and maximum of the four ages.\nThus, we note that the R programming language provides a wide range of statistical operations that can be performed on vectors for data analysis and modeling. Vectors are clearly a potent and versatile data structure that can be utilized in a variety of ways.\n\n\n\nHere are some common string operations that can be conducted using the provided vector examples.\n\nSubstring: The substr() function can be used to extract a substring from a character vector. To extract the first three characters of each name in the “names” vector, for instance, we can use:\n\n\nsubstr(names, 1, 3)\n\n[1] \"Ash\" \"Bul\" \"Cha\" \"Div\"\n\n\nThis returns a new character vector containing the initial three letters of each name (“Ash”, “Bul”, “Cha”, and “Div”).\n\nConcatenation: Using the paste() function, we can concatenate two or more character vectors into a singular vector. To create a new vector containing the names and ages of the individuals, for instance, we can use:\n\n\npersons &lt;- paste(names, ages)\npersons\n\n[1] \"Ashok 72\" \"Bullu 49\" \"Charu 46\" \"Divya 42\"\n\n\nThis will generate a new eight-element character vector containing the name and age of each individual, separated by a space.\n\nCase Conversion: The toupper() and tolower() functions can be used to convert the case of characters within a character vector. To convert the “names” vector to uppercase letters, for instance, we can use:\n\n\ntoupper(names)\n\n[1] \"ASHOK\" \"BULLU\" \"CHARU\" \"DIVYA\"\n\n\nThis will generate a new character vector with all of the names converted to uppercase.\n\nPattern Matching: Using the grep() and grepl() functions, we can search for a pattern within the elements of a character vector. To find the names in the “names” vector that contain the letter “a”, for instance, we can use:\n\n\ngrep(\"a\", names)\n\n[1] 3 4\n\n\nThis returns a vector containing the indexes of the “names” vector elements that contain the letter “a.”\n\nRegular Expressions: We can use regular expressions with the grep() and grepl() functions to search for patterns in the elements of a character vector. To find the names in the “names” vector that begin with the letter “C”, for instance, we can use:\n\n\ngrep(\"^C\", names)\n\n[1] 3\n\n\nThis returns a vector containing the indexes of the elements in “names” that begin with the letter “C.” [1]\n\n\n\n\n[1]\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\nR Core Team. (2022). Vectors, Lists, and Arrays. R Documentation. https://cran.r-project.org/doc/manuals/r-release/R-intro.html#vectors-lists-and-arrays\nWickham, H., & Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media, Inc."
  },
  {
    "objectID": "04DataStructures.html#popular-data-structures",
    "href": "04DataStructures.html#popular-data-structures",
    "title": "Data Structures",
    "section": "",
    "text": "The R programming language includes a number of data structures that are frequently employed in data analysis and statistical modeling. These are some of the most popular data structures in R:\n\nVector: A vector is a one-dimensional array that stores identical data types, such as numeric, character, or logical. The “c()” function can be used to create vectors, and indexing can be used to access individual vector elements.\nFactor: A factor is a vector representing categorical data, with each distinct value or category represented as a level. Using indexing, individual levels of a factor can be accessed using the “factor()” function.\nDataframe: Similar to a spreadsheet, a data frame is a two-dimensional table-like structure that can store various types of data in columns. The “data.frame()” function can be used to construct data frames, and individual elements can be accessed using row and column indexing.\nMatrix: A matrix is a two-dimensional array of data with identical rows and columns. The “matrix()” function can be used to construct matrices, and individual elements can be accessed using row and column indexing.\nArray: An array is a multidimensional data structure that can contain data of the same data type in user-specified dimensions. Arrays can be constructed using the “array()” function, and elements can be accessed using multiple indexing.\nList: A list is an object that may comprise elements of various data types, including vectors, matrices, data frames, and even other lists. The “list()” function can be used to construct lists, while indexing can be used to access individual elements.\n\nThese data structures are helpful for storing and manipulating data in R, and they can be utilized in numerous applications, such as statistical analysis and data visualization.\nWe will focus our attention on Vectors, Factors and Dataframes, since we believe that these are the three most useful data structures. [1]"
  },
  {
    "objectID": "04DataStructures.html#vectors",
    "href": "04DataStructures.html#vectors",
    "title": "Data Structures",
    "section": "",
    "text": "A vector is a fundamental data structure in R that can hold a sequence of values of the same data type, such as integers, numeric, character, or logical values.\nA vector can be created using the c() function.\nR supports two forms of vectors: atomic vectors and lists. Atomic vectors are limited to containing elements of a single data type, such as numeric or character. Lists, on the other hand, can contain elements of various data types and structures. [1]\n\n\n\n\nThe following R code creates a numeric vector, a character vector and a logical vector respectively.\n\n\n# Read data into vectors\nnames &lt;- c(\"Ashok\", \"Bullu\", \"Charu\", \"Divya\")\nages &lt;- c(72, 49, 46, 42)\nfemales &lt;- c(FALSE, TRUE, TRUE, TRUE)\n\n\nThe c() function is employed to combine the four character elements into a single vector.\nCommas separate the elements of the vector within the parentheses.\nIndividual elements of the vector can be accessed via indexing, which utilizes square brackets []. For instance, names[1] returns “Ashok”, while names[3] returns “Charu”.\nWe can also perform operations such as categorizing and filtering on the entire vector. For instance, sort(names) returns a vector of sorted names, whereas names[names!= “Bullu”] returns a vector of names excluding “Bullu.”\n\n\n\n\nVectors can be used to perform the following vector operations:\n\nAccessing Elements: We can use indexing with square brackets to access individual elements of a vector. To access the second element of the “names” vector, for instance, we can use:\n\n\nnames[2]\n\n[1] \"Bullu\"\n\n\nThis returns “Bullu”, the second element of the “names” vector.\n\nConcatenation: The “c()” function can be used to combine multiple vectors into a single vector. For instance, to combine the “names” and “ages” vectors into the “people” vector, we can use:\n\n\npersons &lt;- c(names, ages)\npersons\n\n[1] \"Ashok\" \"Bullu\" \"Charu\" \"Divya\" \"72\"    \"49\"    \"46\"    \"42\"   \n\n\nThis generates an eight-element vector containing the names and ages of the four people.\n\nSubsetting: We can use indexing with a logical condition to construct a new vector that contains a subset of elements from an existing vector. For instance, to construct a new vector named “female_names” containing only the females’ names, we can use:\n\n\nfemale_names &lt;- names[females == TRUE]\nfemale_names\n\n[1] \"Bullu\" \"Charu\" \"Divya\"\n\n\nThis generates a new vector comprising three elements containing the names of the three females (“Bullu”, “Charu”, and “Divya”).\n\nArithmetic Operations: We can perform element-wise arithmetic operations on vectors. To calculate the sum of the “ages” vector, for instance, we can use:\n\n\nsum(ages)\n\n[1] 209\n\n\nThis returns 209, the sum of the four ages.\n\nLogical Operations: We can perform logical operations on vectors, which are also executed element-by-element. To create a new vector titled “middle_age” that indicates whether each individual is 45 to 55 years old, for instance, we can use:\n\n\nmiddle_age &lt;- (ages &gt;= 45) & (ages &lt;= 55)\nmiddle_age\n\n[1] FALSE  TRUE  TRUE FALSE\n\n\nThis generates a new vector with four elements containing logical values indicating whether each person is between 45 and 55 years of age.\nTo test whether any of the elements in the “ages” vector are greater than 50, we can use:\n\nany(ages &gt; 50)\n\n[1] TRUE\n\n\n\nUnique Values: We can find the unique values in a vector using the “unique()” function. For example, to find the unique values in the “ages” vector, we can use:\n\n\nunique(ages)\n\n[1] 72 49 46 42\n\n\n\nSorting: We can sort a vector in ascending or descending order using the “sort()” function. For example, to sort the “ages” vector in descending order, we can use:\n\n\nsort(ages, decreasing = TRUE)\n\n[1] 72 49 46 42\n\n\n\n\n\n\nLength: The length represents the count of the number of elements in a vector.\n\n\nlength(ages)\n\n[1] 4\n\n\n\nMaximum and Minimum: The maximum and minimum values are the vector’s greatest and smallest values, respectively.\nRange: The range is a measure of the spread that represents the difference between the maximum and minimum values in a vector.\n\n\nmin(ages)\n\n[1] 42\n\nmax(ages)\n\n[1] 72\n\nrange(ages)\n\n[1] 42 72\n\n\n\nMean: The mean is a central tendency measure that represents the average value of a vector’s elements.\nStandard Deviation: The standard deviation is a measure of dispersion that reflects the amount of variation in a vector’s elements.\nVariance: The variance is another measure of the spread. It is square of the Standard Deviation.\n\n\nmean(ages)\n\n[1] 52.25\n\nsd(ages)\n\n[1] 13.47529\n\nvar(ages)\n\n[1] 181.5833\n\n\n\nMedian: The median is a measure of central tendency that represents the middle value of a sorted vector.\n\n\nmedian(ages)\n\n[1] 47.5\n\n\n\nQuantiles: The quantiles are a set of cut-off points that divide a sorted vector into equal-sized groups.\n\n\nquantile(ages)\n\n   0%   25%   50%   75%  100% \n42.00 45.00 47.50 54.75 72.00 \n\n\nThis will return a set of five values, representing the minimum, first quartile, median, third quartile, and maximum of the four ages.\nThus, we note that the R programming language provides a wide range of statistical operations that can be performed on vectors for data analysis and modeling. Vectors are clearly a potent and versatile data structure that can be utilized in a variety of ways.\n\n\n\nHere are some common string operations that can be conducted using the provided vector examples.\n\nSubstring: The substr() function can be used to extract a substring from a character vector. To extract the first three characters of each name in the “names” vector, for instance, we can use:\n\n\nsubstr(names, 1, 3)\n\n[1] \"Ash\" \"Bul\" \"Cha\" \"Div\"\n\n\nThis returns a new character vector containing the initial three letters of each name (“Ash”, “Bul”, “Cha”, and “Div”).\n\nConcatenation: Using the paste() function, we can concatenate two or more character vectors into a singular vector. To create a new vector containing the names and ages of the individuals, for instance, we can use:\n\n\npersons &lt;- paste(names, ages)\npersons\n\n[1] \"Ashok 72\" \"Bullu 49\" \"Charu 46\" \"Divya 42\"\n\n\nThis will generate a new eight-element character vector containing the name and age of each individual, separated by a space.\n\nCase Conversion: The toupper() and tolower() functions can be used to convert the case of characters within a character vector. To convert the “names” vector to uppercase letters, for instance, we can use:\n\n\ntoupper(names)\n\n[1] \"ASHOK\" \"BULLU\" \"CHARU\" \"DIVYA\"\n\n\nThis will generate a new character vector with all of the names converted to uppercase.\n\nPattern Matching: Using the grep() and grepl() functions, we can search for a pattern within the elements of a character vector. To find the names in the “names” vector that contain the letter “a”, for instance, we can use:\n\n\ngrep(\"a\", names)\n\n[1] 3 4\n\n\nThis returns a vector containing the indexes of the “names” vector elements that contain the letter “a.”\n\nRegular Expressions: We can use regular expressions with the grep() and grepl() functions to search for patterns in the elements of a character vector. To find the names in the “names” vector that begin with the letter “C”, for instance, we can use:\n\n\ngrep(\"^C\", names)\n\n[1] 3\n\n\nThis returns a vector containing the indexes of the elements in “names” that begin with the letter “C.” [1]"
  },
  {
    "objectID": "04DataStructures.html#references",
    "href": "04DataStructures.html#references",
    "title": "Data Structures",
    "section": "",
    "text": "[1]\nR Core Team. (2021). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\nR Core Team. (2022). Vectors, Lists, and Arrays. R Documentation. https://cran.r-project.org/doc/manuals/r-release/R-intro.html#vectors-lists-and-arrays\nWickham, H., & Grolemund, G. (2016). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media, Inc."
  },
  {
    "objectID": "02RPackages.html",
    "href": "02RPackages.html",
    "title": "R Packages",
    "section": "",
    "text": "R packages are collections of code, data, and documentation that enhance the capabilities of R, a programming language and software environment used for statistical computing and graphics.\nR packages are created by R users and developers and provide additional tools, functions, and datasets that serve various purposes, such as data analysis, visualization, and machine learning.\nR packages can be obtained from various sources, including the Comprehensive R Archive Network (CRAN), Bioconductor, GitHub, and other online repositories.\nTo utilize R packages, they can be imported into R using the library() function, allowing access to the functions and data within them for use in R scripts and interactive sessions. [1]\n\n\n\nThere are numerous advantages to using R packages:\n\nReusability: R packages enable users to write code that is readily reusable across applications. Once a package has been created and published, others can install and use it, sparing them time and effort in coding.\nCollaboration: Individuals or teams can develop packages collaboratively, enabling the sharing of code, data, and ideas. This promotes collaboration within the R community and the creation of new tools and techniques.\nStandardization: Packages help standardize the code and methodology used for particular duties, making it simpler for users to comprehend and replicate the work of others. This decreases the possibility of errors and improves the dependability of results.\nScalability: Packages can manage large data sets and sophisticated analyses, enabling users to scale up their work to larger, more complex problems.\nAccessibility: R packages are freely available and can be installed on a variety of operating systems, making them accessible to a broad spectrum of users. [1]\n\n\n\n\n\nThe Comprehensive R Archive Network (CRAN) is a global network of servers dedicated to maintaining and distributing R packages. These packages consist of code, data, and documentation that enhance the functionality of R.\nCRAN serves as a centralized and well-organized repository, simplifying the process for users to find, obtain, and install the required packages. With thousands of packages available, users can utilize the install.packages() function in R to download and install them.\nCRAN categorizes packages into various groups such as graphics, statistics, and machine learning, facilitating easy discovery of relevant packages based on specific needs.\nCRAN is maintained by the R Development Core Team and is accessible to anyone with an internet connection, ensuring broad availability and accessibility. [2]\n\n\n\n\n\nThe install.packages() function can be employed to install R packages.\nFor instance, to install the ggplot2 package in R, you would execute the following code:\n\n\ninstall.packages(\"ggplot2\")\n\n\nExecuting the code provided will download and install the ggplot2 package, along with any necessary dependencies, on your system.\nIt’s important to remember that a package needs to be installed only once on your system. Once installed, you can easily import the package into your R session using the library() function.\nFor example, to import the ggplot2 package in R, you can execute the following code:\n\n\nlibrary(ggplot2)\n\n\nBy executing the provided code, you will enable access to the functions and datasets of the ggplot2 package for use within your R session.\n\n\n\nThere are several popular R packages useful for summarizing, transforming, manipulating and visualizing data. Here is a list of some commonly used packages along with a brief description of each:\n\ndplyr: A grammar of data manipulation, providing a set of functions for easy and efficient data manipulation tasks like filtering, summarizing, and transforming data frames.\ntidyr: Provides tools for tidying data, which involves reshaping data sets to facilitate analysis by ensuring each variable has its own column and each observation has its own row.\nplyr: Offers a set of functions for splitting, applying a function, and combining results, allowing for efficient data manipulation and summarization.\nreshape2: Provides functions for transforming data between different formats, such as converting data from wide to long format and vice versa.\ndata.table: A high-performance package for data manipulation, offering fast and memory-efficient tools for tasks like filtering, aggregating, and joining large data sets.\nlubridate: Designed specifically for working with dates and times, it simplifies common tasks like parsing, manipulating, and formatting date-time data.\nstringr: Offers a consistent and intuitive set of functions for working with strings, including pattern matching, string manipulation, and string extraction.\nmagrittr: Provides a simple and readable syntax for composing data manipulation and transformation operations, making code more readable and expressive.\nggplot2: A powerful and flexible package for creating beautiful and customizable data visualizations using a layered grammar of graphics approach.\nplotly: Enables interactive and dynamic data visualizations, allowing users to create interactive plots, charts, and dashboards that can be explored and analyzed. [2]\n\n\n\n\n\nAs an illustration, here is a sample code for a scatterplot created using the ggplot2 package.\nFigure 1 considers the mtcars dataset inbuilt in R and illustrates the relationship between the weight of cars measured in thousands of pounds and the corresponding mileage measured in miles per gallon.\n\nlibrary(ggplot2)\ndata(mtcars)\n\nggplot(mtcars, aes(wt, mpg)) + \n  geom_point() \n\n\n\n\nFigure 1: Scatterplot of Car Mileage with Car Weight\n\n\n\n\n\n\nTo seek assistance with an R package, you can explore the following avenues:\n\nDocumentation: Most R packages come with comprehensive documentation that explains the package’s functions, datasets, and provides usage examples. You can access the documentation by using the help() function or typing ?package_name in the R console, where “package_name” is the name of the specific package you want to learn about.\nIntegrated help system: R has an integrated help system that offers documentation and demonstrations for functions and packages. In the R console, you can access the help system by typing help(topic) or ?topic, where “topic” represents the name of the function or package you need assistance with.\nOnline Resources: Numerous online resources are available for obtaining help with R packages. Blogs, forums, and question-and-answer platforms like Stack Overflow offer valuable insights and solutions to specific problems. These platforms are particularly helpful for finding answers to specific questions and obtaining general guidance on package usage. [3]\n\n\n\n\n\n[1] Hadley, W., & Chang, W. (2018). R Packages. O’Reilly Media.\nHester, J., & Wickham, H. (2018). R Packages: A guide based on modern practices. O’Reilly Media.\nWickham, H. (2015). R Packages: Organize, Test, Document, and Share Your Code. O’Reilly Media.\n[2] Wickham, H., François, R., Henry, L., & Müller, K. (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. Retrieved from https://CRAN.R-project.org/package=dplyr\nWickham, H., & Henry, L. (2020). tidyr: Tidy Messy Data. R package version 1.1.4. Retrieved from https://CRAN.R-project.org/package=tidyr\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., & Woo, K. (2021). ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. R package version 3.3.5. Retrieved from https://CRAN.R-project.org/package=ggplot2\nWickham, H. (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, 40(1), 1-29.\nWickham, H. (2019). reshape2: Flexibly Reshape Data: A Reboot of the Reshape Package. R package version 1.4.4. Retrieved from https://CRAN.R-project.org/package=reshape2\nDowle, M., Srinivasan, A., Gorecki, J., Chirico, M., Stetsenko, P., Short, T., ... & Lianoglou, S. (2021). data.table: Extension of data.frame. R package version 1.14.0. Retrieved from https://CRAN.R-project.org/package=data.table\nGrolemund, G., & Wickham, H. (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25.\nWickham, H. (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. Retrieved from https://CRAN.R-project.org/package=stringr\nSievert, C. (2021). plotly: Create Interactive Web Graphics via ‘plotly.js’. R package version 4.10.0. Retrieved from https://CRAN.R-project.org/package=plotly\nBache, S. M., & Wickham, H. (2014). magrittr: A Forward-Pipe Operator for R. R package version 2.0.1. Retrieved from https://CRAN.R-project.org/package=magrittr\n[3] R Core Team. (2021). Writing R Extensions. Retrieved from https://cran.r-project.org/doc/manuals/r-release/R-exts.html\nWickham, H., & Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media.\nRStudio Team. (2020). RStudio: Integrated Development Environment for R. Retrieved from https://www.rstudio.com/"
  },
  {
    "objectID": "02RPackages.html#benefits-of-r-packages",
    "href": "02RPackages.html#benefits-of-r-packages",
    "title": "R Packages",
    "section": "",
    "text": "There are numerous advantages to using R packages:\n\nReusability: R packages enable users to write code that is readily reusable across applications. Once a package has been created and published, others can install and use it, sparing them time and effort in coding.\nCollaboration: Individuals or teams can develop packages collaboratively, enabling the sharing of code, data, and ideas. This promotes collaboration within the R community and the creation of new tools and techniques.\nStandardization: Packages help standardize the code and methodology used for particular duties, making it simpler for users to comprehend and replicate the work of others. This decreases the possibility of errors and improves the dependability of results.\nScalability: Packages can manage large data sets and sophisticated analyses, enabling users to scale up their work to larger, more complex problems.\nAccessibility: R packages are freely available and can be installed on a variety of operating systems, making them accessible to a broad spectrum of users. [1]"
  },
  {
    "objectID": "02RPackages.html#comprehensive-r-archive-network-cran",
    "href": "02RPackages.html#comprehensive-r-archive-network-cran",
    "title": "R Packages",
    "section": "",
    "text": "The Comprehensive R Archive Network (CRAN) is a global network of servers dedicated to maintaining and distributing R packages. These packages consist of code, data, and documentation that enhance the functionality of R.\nCRAN serves as a centralized and well-organized repository, simplifying the process for users to find, obtain, and install the required packages. With thousands of packages available, users can utilize the install.packages() function in R to download and install them.\nCRAN categorizes packages into various groups such as graphics, statistics, and machine learning, facilitating easy discovery of relevant packages based on specific needs.\nCRAN is maintained by the R Development Core Team and is accessible to anyone with an internet connection, ensuring broad availability and accessibility. [2]"
  },
  {
    "objectID": "02RPackages.html#installing-a-r-package",
    "href": "02RPackages.html#installing-a-r-package",
    "title": "R Packages",
    "section": "",
    "text": "The install.packages() function can be employed to install R packages.\nFor instance, to install the ggplot2 package in R, you would execute the following code:\n\n\ninstall.packages(\"ggplot2\")\n\n\nExecuting the code provided will download and install the ggplot2 package, along with any necessary dependencies, on your system.\nIt’s important to remember that a package needs to be installed only once on your system. Once installed, you can easily import the package into your R session using the library() function.\nFor example, to import the ggplot2 package in R, you can execute the following code:\n\n\nlibrary(ggplot2)\n\n\nBy executing the provided code, you will enable access to the functions and datasets of the ggplot2 package for use within your R session.\n\n\n\nThere are several popular R packages useful for summarizing, transforming, manipulating and visualizing data. Here is a list of some commonly used packages along with a brief description of each:\n\ndplyr: A grammar of data manipulation, providing a set of functions for easy and efficient data manipulation tasks like filtering, summarizing, and transforming data frames.\ntidyr: Provides tools for tidying data, which involves reshaping data sets to facilitate analysis by ensuring each variable has its own column and each observation has its own row.\nplyr: Offers a set of functions for splitting, applying a function, and combining results, allowing for efficient data manipulation and summarization.\nreshape2: Provides functions for transforming data between different formats, such as converting data from wide to long format and vice versa.\ndata.table: A high-performance package for data manipulation, offering fast and memory-efficient tools for tasks like filtering, aggregating, and joining large data sets.\nlubridate: Designed specifically for working with dates and times, it simplifies common tasks like parsing, manipulating, and formatting date-time data.\nstringr: Offers a consistent and intuitive set of functions for working with strings, including pattern matching, string manipulation, and string extraction.\nmagrittr: Provides a simple and readable syntax for composing data manipulation and transformation operations, making code more readable and expressive.\nggplot2: A powerful and flexible package for creating beautiful and customizable data visualizations using a layered grammar of graphics approach.\nplotly: Enables interactive and dynamic data visualizations, allowing users to create interactive plots, charts, and dashboards that can be explored and analyzed. [2]"
  },
  {
    "objectID": "02RPackages.html#sample-plot",
    "href": "02RPackages.html#sample-plot",
    "title": "R Packages",
    "section": "",
    "text": "As an illustration, here is a sample code for a scatterplot created using the ggplot2 package.\nFigure 1 considers the mtcars dataset inbuilt in R and illustrates the relationship between the weight of cars measured in thousands of pounds and the corresponding mileage measured in miles per gallon.\n\nlibrary(ggplot2)\ndata(mtcars)\n\nggplot(mtcars, aes(wt, mpg)) + \n  geom_point() \n\n\n\n\nFigure 1: Scatterplot of Car Mileage with Car Weight\n\n\n\n\n\n\nTo seek assistance with an R package, you can explore the following avenues:\n\nDocumentation: Most R packages come with comprehensive documentation that explains the package’s functions, datasets, and provides usage examples. You can access the documentation by using the help() function or typing ?package_name in the R console, where “package_name” is the name of the specific package you want to learn about.\nIntegrated help system: R has an integrated help system that offers documentation and demonstrations for functions and packages. In the R console, you can access the help system by typing help(topic) or ?topic, where “topic” represents the name of the function or package you need assistance with.\nOnline Resources: Numerous online resources are available for obtaining help with R packages. Blogs, forums, and question-and-answer platforms like Stack Overflow offer valuable insights and solutions to specific problems. These platforms are particularly helpful for finding answers to specific questions and obtaining general guidance on package usage. [3]"
  },
  {
    "objectID": "02RPackages.html#references",
    "href": "02RPackages.html#references",
    "title": "R Packages",
    "section": "",
    "text": "[1] Hadley, W., & Chang, W. (2018). R Packages. O’Reilly Media.\nHester, J., & Wickham, H. (2018). R Packages: A guide based on modern practices. O’Reilly Media.\nWickham, H. (2015). R Packages: Organize, Test, Document, and Share Your Code. O’Reilly Media.\n[2] Wickham, H., François, R., Henry, L., & Müller, K. (2021). dplyr: A Grammar of Data Manipulation. R package version 1.0.7. Retrieved from https://CRAN.R-project.org/package=dplyr\nWickham, H., & Henry, L. (2020). tidyr: Tidy Messy Data. R package version 1.1.4. Retrieved from https://CRAN.R-project.org/package=tidyr\nWickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., & Woo, K. (2021). ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. R package version 3.3.5. Retrieved from https://CRAN.R-project.org/package=ggplot2\nWickham, H. (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, 40(1), 1-29.\nWickham, H. (2019). reshape2: Flexibly Reshape Data: A Reboot of the Reshape Package. R package version 1.4.4. Retrieved from https://CRAN.R-project.org/package=reshape2\nDowle, M., Srinivasan, A., Gorecki, J., Chirico, M., Stetsenko, P., Short, T., ... & Lianoglou, S. (2021). data.table: Extension of data.frame. R package version 1.14.0. Retrieved from https://CRAN.R-project.org/package=data.table\nGrolemund, G., & Wickham, H. (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25.\nWickham, H. (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. Retrieved from https://CRAN.R-project.org/package=stringr\nSievert, C. (2021). plotly: Create Interactive Web Graphics via ‘plotly.js’. R package version 4.10.0. Retrieved from https://CRAN.R-project.org/package=plotly\nBache, S. M., & Wickham, H. (2014). magrittr: A Forward-Pipe Operator for R. R package version 2.0.1. Retrieved from https://CRAN.R-project.org/package=magrittr\n[3] R Core Team. (2021). Writing R Extensions. Retrieved from https://cran.r-project.org/doc/manuals/r-release/R-exts.html\nWickham, H., & Grolemund, G. (2016). R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media.\nRStudio Team. (2020). RStudio: Integrated Development Environment for R. Retrieved from https://www.rstudio.com/"
  }
]